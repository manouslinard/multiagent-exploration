# -*- coding: utf-8 -*-
"""Swarm_RL-Manousos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cm72UF410of_mpOD2MRWVLuUruF6G_N3
"""

import time
import copy
import random
import functools
import numpy as np
import warnings
warnings.filterwarnings('ignore')
from google.colab import drive
import pandas as pd

drive.mount('/content/drive')

"""The Agent Class:"""

class Agent:

  def __init__(self, start: tuple, goal: tuple, real_stage, view_range=1):
      self.x = start[0]
      self.y = start[1]
      self.goal = goal
      self.view_range = view_range
      self.explored_stage = np.full_like(real_stage, -1)
      self.explored_stage[self.x, self.y] = 0
      self.agent_view(real_stage)
      self.start_time = time.time()

  def agent_view(self, real_stage):
    """ Refreshes the explored map of the agent (sees up, down, left, right). """
    up_obs, upleft_obs, upright_obs, down_obs, downleft_obs, downright_obs, left_obs, right_obs = False, False, False, False, False, False, False, False
    for i in range(self.view_range):
      if self.x > i:  # checks up
        tmp_x = self.x - i - 1
        if not up_obs:  # stops if it sees obstacle
          self.explored_stage[(tmp_x, self.y)] = real_stage[(tmp_x, self.y)]
          if real_stage[(tmp_x, self.y)]:
            up_obs = True
        if self.y > i and not upleft_obs:  # up-left
          if not upleft_obs:  # stops if it sees obstacle
            self.explored_stage[(tmp_x, self.y - i - 1)] = real_stage[(tmp_x, self.y - i - 1)]
            if real_stage[(tmp_x, self.y - i - 1)]:
              upleft_obs = True
        if self.y < len(real_stage[0]) - i - 1: # up-right
          if not upright_obs:  # stops if it sees obstacle
            self.explored_stage[(tmp_x, self.y + i + 1)] = real_stage[(tmp_x, self.y + i + 1)]
            if real_stage[(tmp_x, self.y + i + 1)]:
              upright_obs = True

      if self.x < len(real_stage) - i - 1:  # checks down:
        tmp_x = self.x + i + 1
        if not down_obs:
          self.explored_stage[(tmp_x, self.y)] = real_stage[(tmp_x, self.y)]
          if real_stage[(tmp_x, self.y)]:
            down_obs = True
        if self.y > i:  # down-left
          if not downleft_obs:
            self.explored_stage[(tmp_x, self.y - i - 1)] = real_stage[(tmp_x, self.y - i - 1)]
            if real_stage[(tmp_x, self.y - i - 1)]:
              downleft_obs = True
        if self.y < len(real_stage[0]) - i - 1: # down-right
          if not downright_obs:
            self.explored_stage[(tmp_x, self.y + i + 1)] = real_stage[(tmp_x, self.y + i + 1)]
            if real_stage[(tmp_x, self.y + i + 1)]:
              downright_obs = True

      if self.y > i and not left_obs:  # left (& stops if it sees obstacle)
        self.explored_stage[(self.x, self.y - i - 1)] = real_stage[(self.x, self.y - i - 1)]
        if real_stage[(self.x, self.y - i - 1)]:
          left_obs = True

      if self.y < len(real_stage[0]) - i - 1 and not right_obs: # right (& stops if it sees obstacle)
        self.explored_stage[(self.x, self.y + i + 1)] = real_stage[(self.x, self.y + i + 1)]
        if real_stage[(self.x, self.y + i + 1)]:
          right_obs = True

    self.explored_stage[self.explored_stage == 2] = 0

  def check_goal(self):
    if (self.x, self.y) == self.goal:
      return True
    return False

"""A* Algorithm:"""

class Node:
    def __init__(self, x, y, g_cost, h_cost):
        self.x = x
        self.y = y
        self.g_cost = g_cost
        self.h_cost = h_cost
        self.parent = None

    def f_cost(self):
        return self.g_cost + self.h_cost

def is_valid(x, y, grid):
    # Checks if the x and y are within grid + if no obs in (x, y).
    rows, cols = grid.shape
    return 0 <= x < rows and 0 <= y < cols and grid[x, y] <= 0

def a_star(grid, start, end):
    directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]  # Right, Down, Left, Up
    rows, cols = grid.shape
    grid2 = copy.deepcopy(grid)
    grid2[grid2 == -1] = 0
    grid2[grid2 == 2] = 0
    draw_maze(grid)

    open_set = []
    closed_set = set()

    start_node = Node(start[0], start[1], 0, 0)
    open_set.append(start_node)

    while open_set:
        current_node = min(open_set, key=lambda node: node.f_cost())
        open_set.remove(current_node)
        closed_set.add((current_node.x, current_node.y))

        if (current_node.x, current_node.y) == end:
            path = []
            while current_node:
                path.insert(0, (current_node.x, current_node.y))
                current_node = current_node.parent
            return path

        for dx, dy in directions:
            new_x, new_y = current_node.x + dx, current_node.y + dy
            if is_valid(new_x, new_y, grid2) and (new_x, new_y) not in closed_set:
                g_cost = current_node.g_cost + 1
                h_cost = abs(new_x - end[0]) + abs(new_y - end[1])
                new_node = Node(new_x, new_y, g_cost, h_cost)
                new_node.parent = current_node
                if new_node not in open_set:
                    open_set.append(new_node)

    return None

"""Create a stage with obstacles (1) and free path (0)."""

def generate_stage(rows: int, cols: int, obs_prob = 0.2):

  # generate obstacles with obs_prob probability
  num_obstacles = int(rows * cols * obs_prob)

  stage = np.full((rows, cols), 0)

  # Set 1s at random positions for the specified percentage
  indices = np.random.choice(rows * cols, num_obstacles, replace=False)
  stage.flat[indices] = 1

  return stage

""" Creates the "explored" stage, which at the start everything is not explored (-1) and put the agents there (2)."""

def generate_agents(real_stage, num_agents: int = 1, view_range: int = 1):

  agents = []

  if num_agents <= 0:
    num_agents = 1

  zero_coordinates = list(zip(*np.where(real_stage == 0)))
  goal = random.choice(zero_coordinates)
  # Create the "explored" stage
  for _ in range(num_agents):
    if zero_coordinates:
      start = random.choice(zero_coordinates)
      zero_coordinates.remove(start)
      agents.append(Agent((start[0], start[1]), (goal[0], goal[1]), real_stage, view_range))
    else:
      break

  return agents

"""Function to concat all agents explored stages (returns the total explored stage):"""

def update_total_explored(agents):
  if len(agents) == 0:
    return

  total_explored = np.full(agents[0].explored_stage.shape, -1)

  for a in agents:
    total_explored[total_explored == -1] = a.explored_stage[total_explored == -1]
    total_explored[total_explored == 2] = 0

  for a in agents:
    if not a.check_goal():  # if agent has reached goal -> collidable (as if it is removed from the stage).
      total_explored[a.x, a.y] = 2

  # Total explored contains the concats of all agents stages:
  for a in agents:
    a.explored_stage = copy.deepcopy(total_explored)

  return total_explored

"""Calculates the explored percentage of the concat stage:"""

def calculate_expl_percentage(total_explored):
  num_minus_1 = np.sum(total_explored == -1)
  explored_percentage = 1 - (num_minus_1 / (total_explored.shape[0] * total_explored.shape[1]))
  return explored_percentage

"""Function for testing astar:"""

def move_astar(start_grid, start_agents, max_episodes=100, debug=True):

  grid = copy.deepcopy(start_grid)

  agents = copy.deepcopy(start_agents)

  for agent in agents:
      grid[agent.x, agent.y] = 2  # Mark initial agent positions
  total_explored = update_total_explored(agents)
  prev_tot_expl = copy.deepcopy(total_explored)
  episode = 0
  total_agents = len(agents)

  avg_eps_time = []
  avg_agent_time = []

  while any((agent.x, agent.y) != agent.goal for agent in agents) and episode < max_episodes:
      eps_start_time = time.time()
      episode += 1
      # print(episode)
      if debug:
          print(total_explored)

      for agent in agents:
          if (agent.x, agent.y) == agent.goal:
              total_explored = update_total_explored(agents)
              agents.remove(agent)
              continue  # Agent has reached its goal

          print(agent.x, agent.y, agent.goal)
          path = a_star(agent.explored_stage, (agent.x, agent.y), agent.goal)
          print(path)
          if path:
              if agent.explored_stage[path[1]] != 2:
                grid[agent.x, agent.y] = 0  # Mark the old position as unoccupied
                agent.x, agent.y = path[1]  # Update agent position
                grid[agent.x, agent.y] = 2  # Mark the new position as occupied by agent
                if agent.check_goal():
                  avg_agent_time.append(time.time() - agent.start_time)
              # print(grid)
          agent.agent_view(start_grid)
          total_explored = update_total_explored(agents)
          print(calculate_expl_percentage(total_explored))
      avg_eps_time.append(time.time() - eps_start_time)
      if np.array_equal(prev_tot_expl, total_explored): # stops if no agents have moved.
          break
      prev_tot_expl = copy.deepcopy(total_explored)

  if debug:
      print(total_explored)
  return calculate_expl_percentage(total_explored), len(avg_agent_time) / total_agents, total_explored, np.mean(avg_eps_time), np.mean(avg_agent_time)

"""Manual Examples:"""

grid = np.array([[0, 0, 1, 0, 0],
                 [1, 0, 0, 0, 1],
                 [1, 0, 0, 0, 1],
                 [0, 0, 1, 0, 0],
                 [0, 0, 0, 0, 0]])

print("LESS OBSTACLES STAGE")
agents = [Agent((0, 0), (4, 4), grid, 2), Agent((0, 4), (4, 0), grid),]
res = move_astar(grid, agents)
print(f"Total Coverage Percentage {res[0]} / Agents Finished: {res[1]} / Average Episode Time: {res[3]} / Average Agent Finish Time : {res[4]}")
print(f"Final Explored Stage\n{res[2]}")

grid = np.array([[0, 0, 1, 1, 0],
                 [0, 1, 1, 0, 1],
                 [0, 0, 1, 0, 1],
                 [0, 1, 0, 0, 0],
                 [0, 0, 0, 0, 0]])

print("MANY OBSTACLES STAGE")
agents = [Agent((0, 0), (4, 4), grid), Agent((0, 1), (4, 4), grid)]
res = move_astar(grid, agents)
print(f"Total Coverage Percentage {res[0]} / Agents Finished: {res[1]} / Average Episode Time: {res[3]} / Average Agent Finish Time : {res[4]}")
print(f"Final Explored Stage\n{res[2]}")

"""Function for maze creation. [Source](https://medium.com/@msgold/using-python-to-create-and-solve-mazes-672285723c96)."""

from queue import Queue

def create_maze(rows, cols, obs_prob=0.8):
    rows = int(rows / 2)
    cols = int(cols / 2)

    maze = np.ones((rows*2+1, cols*2+1))

    x, y = (0, 0)

    stack = [(x, y)]
    while len(stack) > 0:
        x, y = stack[-1]

        directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]
        random.shuffle(directions)

        for dx, dy in directions:
            nx, ny = x + dx, y + dy
            if nx >= 0 and ny >= 0 and nx < rows and ny < cols and maze[2*nx+1, 2*ny+1] == 1:
                maze[2*nx+1, 2*ny+1] = 0
                maze[2*x+1+dx, 2*y+1+dy] = 0
                stack.append((nx, ny))
                break
        else:
            stack.pop()

    for row in range(rows*2+1):
        for col in range(cols*2+1):
            if random.random() >= obs_prob:
                maze[row][col] = 0

    return maze

"""Function to plot the grid/maze:"""

import matplotlib.pyplot as plt

def draw_maze(maze, path=None):
    fig, ax = plt.subplots(figsize=(10,10))

    fig.patch.set_edgecolor('white')
    fig.patch.set_linewidth(0)

    ax.imshow(maze, cmap=plt.cm.binary, interpolation='nearest')

    if path is not None:
        x_coords = [x[1] for x in path]
        y_coords = [y[0] for y in path]
        ax.plot(x_coords, y_coords, color='red', linewidth=2)

    ax.set_xticks([])
    ax.set_yticks([])

    plt.show()

"""Function to test astar with many experiments (print averages)."""

def test_astar(num_agents, num_test, start_grid = None, gen_stage_func = None, agent_view_range = 1, debug=True):
  """
  Function to test astar with many experiments (returns averages).
  If you want to give the initial grid, initialize the variable start_grid with your grid
  (and put the gen_stage_func parameter = None).
  If you want to create a different stage for each experiment, put start_grid = None
  and initialize the next parameter (gen_stage_func) like so:
  functools.partial(func_for_grid_gen, rows, cols, obs_prob)
  where func_for_grid_gen is a function for grid generation, rows and cols are the number
  of rows and columns of the grid and obs_prob the probablity of obstacles.
  """
  avg = []
  avg_finish = []
  avg_exp_time = []
  avg_agent_time = []
  avg_eps_time= []

  for _ in range(num_test):
    start_time = time.time()
    if start_grid is None:
      grid = gen_stage_func()
      # print(grid)
    else:
      grid = copy.deepcopy(start_grid)
    agents = generate_agents(real_stage = grid, num_agents = num_agents, view_range = agent_view_range)
    res = move_astar(start_grid=grid, start_agents=agents, debug=False)
    avg.append(res[0])
    avg_finish.append(res[1])
    avg_exp_time.append(time.time() - start_time)
    avg_eps_time.append(res[3])
    avg_agent_time.append(res[4])

  avg_agent_time = [x if not np.isnan(x) else max(avg_agent_time) for x in avg_agent_time]  # replaces nans with max value.
  # Checks again for nans, and replaces them with 1.
  if np.all(np.isnan(avg_agent_time)):
    avg_agent_time = np.where(np.isnan(avg_agent_time), 1, avg_agent_time)

  avg_cover, avg_finish, avg_expt_time, avg_eps_time, avg_agent_time = np.mean(avg), np.mean(avg_finish), np.mean(avg_exp_time), np.mean(avg_eps_time), np.mean(avg_agent_time)
  if debug:
    print(f"Average Coverage Percentage: {avg_cover} / Average Finished: {avg_finish} / Average Experiment Time: {avg_expt_time}s / Average Episode Time: {avg_eps_time} / Average Agent Finish Time : {avg_agent_time}")
  return avg_cover, avg_finish, avg_expt_time, avg_eps_time, avg_agent_time

"""Testing with dynamically generated stages:"""

num_agents = 15
num_test = 10

res=test_astar(num_agents, num_test, None, functools.partial(generate_stage, rows=10, cols=10, obs_prob=0.5))

"""Generate test maze:"""

grid_rows, grid_columns = 30, 30
obs_prob = 0.35
test_maze = create_maze(grid_rows, grid_columns, obs_prob)
draw_maze(test_maze)

"""Solve the test_maze with 20 agents:"""

num_agents = 10 # number of agents.
num_test = 1
res=test_astar(num_agents, num_test, None, functools.partial(create_maze, rows=30, cols=30, obs_prob=0.85), agent_view_range=100)

"""Solve the test_maze with 10 agents:"""

num_agents = 10 # number of agents.
num_test = 20
res=test_astar(num_agents, num_test, None, functools.partial(create_maze, rows=13, cols=13, obs_prob=0.85))

"""Solve the test_maze with 20 agents and max view range:"""

num_agents = 20 # number of agents.
num_test = 20
res=test_astar(num_agents, num_test, None, functools.partial(create_maze, rows=13, cols=13, obs_prob=0.85), agent_view_range=1000)

"""Solve the test_maze with 10 agents and max view range:"""

num_agents = 10 # number of agents.
num_test = 20
res=test_astar(num_agents, num_test, None, functools.partial(create_maze, rows=13, cols=13, obs_prob=0.85), agent_view_range=1000)

"""Solve the test_maze with 5 agents and max view range:"""

num_agents = 5 # number of agents.
num_test = 20
res=test_astar(num_agents, num_test, None, functools.partial(create_maze, rows=13, cols=13, obs_prob=0.85), agent_view_range=1000)

"""Solve the test_maze with 25 agents and max view range:"""

num_agents = 25 # number of agents.
num_test = 20
res=test_astar(num_agents, num_test, None, functools.partial(create_maze, rows=13, cols=13, obs_prob=0.85), agent_view_range=1000)

"""Save experiments on a xlsx file:"""

file_path = '/content/drive/My Drive/astar_swarm.xlsx'

# Initialization Parameters ========
min_num_agents = 3
max_num_agents = 9
min_maze_dim = 10
max_maze_dim = 13
num_test = 100
# =================================

try:
    df = pd.read_excel(file_path)
except FileNotFoundError:
    df = pd.DataFrame(columns=["#_Agents", "Coverage", "Finished_Agents", "Experiment_Time", "Episode_Time", "Agent_Finish_Time", "Dimensions"])

for maze_dim in range(min_maze_dim, max_maze_dim + 1):
  print(f"Maze Dimensions: {maze_dim}x{maze_dim}")
  for num_agent in range(min_num_agents, max_num_agents + 1):
    print(f"  Agent number: {num_agent}")
    avg_cover, avg_finish, avg_expt_time, avg_eps_time, avg_agent_time = test_astar(num_agent, num_test, gen_stage_func=functools.partial(create_maze, rows=maze_dim, cols=maze_dim, obs_prob=0.85), agent_view_range=1000, debug=False)
    new_row = {
        "#_Agents": num_agent,
        "Coverage": avg_cover,
        "Finished_Agents": avg_finish,
        "Experiment_Time": avg_expt_time,
        "Episode_Time": avg_eps_time,
        "Agent_Finish_Time": avg_agent_time,
        "Dimensions": (maze_dim, maze_dim)
    }

    df = df.append(new_row, ignore_index=True)
    df.to_excel(file_path, float_format='%.5f', index=False)

import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler

file_path = '/content/drive/My Drive/astar_swarm.xlsx'
df = pd.read_excel(file_path)

# weights sum up to 0.
weights = {
    'Coverage': 1,
    'Finished_Agents': 1,
    'Experiment_Time': -1,
    'Episode_Time': -1,
    'Agent_Finish_Time': -1,
}

scaler = MinMaxScaler()
df_normalized = pd.DataFrame(scaler.fit_transform(df[['Coverage', 'Finished_Agents', 'Experiment_Time', 'Episode_Time', 'Agent_Finish_Time']]),
                              columns=['Coverage', 'Finished_Agents', 'Experiment_Time', 'Episode_Time', 'Agent_Finish_Time'])

df['Composite_Score'] = (df_normalized['Coverage'] * weights['Coverage'] +
                         df_normalized['Finished_Agents'] * weights['Finished_Agents'] +
                         df_normalized['Experiment_Time'] * weights['Experiment_Time'] +
                         df_normalized['Episode_Time'] * weights['Episode_Time'] +
                         df_normalized['Agent_Finish_Time'] * weights['Agent_Finish_Time'])

# print(df)

avg_scores = df.groupby('#_Agents')['Composite_Score'].mean().reset_index(name='Average_Score')
# print(avg_scores)

plt.plot(avg_scores['#_Agents'], avg_scores['Average_Score'], marker='o', linestyle='-', color='b')
plt.xlabel('# of Agents')
plt.xticks(avg_scores['#_Agents'].astype(int))
plt.ylabel('Average Score')
plt.title("Average Score from 10x10 to 13x13 maze.")
plt.grid(True)
plt.show()

"""**OLD VERSION** of the Agent Class:
```
class Agent:

  def __init__(self, x, y, direction, real_stage, explored_stage):
    self.x = x
    self.y = y
    self.direction = direction  # 'up', 'down', 'left', 'right'
    self.real_stage = real_stage  # contains obstacles and paths
    self.explored_stage = explored_stage  # explored stage (contains agents)

  def move_left(self):
    self.direction = "left"
    if self.y > 0:
      if self.real_stage[(self.x, self.y - 1)] or self.explored_stage[(self.x, self.y - 1)]:  # obs or other agent
        print("obs")
        self.refresh_agent_view()
        return
      self.explored_stage[(self.x, self.y)] = 0
      self.y -= 1
      self.explored_stage[(self.x, self.y)] = 2
      self.refresh_agent_view()

  def move_right(self):
    self.direction = 'right'
    if self.y < len(self.explored_stage[0]) - 1:
      if self.real_stage[(self.x, self.y + 1)] or self.explored_stage[(self.x, self.y + 1)]:  # obs or other agent
        print("obs")
        self.refresh_agent_view()
        return
      self.explored_stage[(self.x, self.y)] = 0
      self.y += 1
      self.explored_stage[(self.x, self.y)] = 2
      self.refresh_agent_view()

  def move_up(self):
    self.direction = 'up'
    if self.x > 0:
      if self.real_stage[(self.x - 1, self.y)] or self.explored_stage[(self.x - 1, self.y)]:  # obs or other agent
        print("obs")
        self.refresh_agent_view()
        return
      self.explored_stage[(self.x, self.y)] = 0
      self.x -= 1
      self.explored_stage[(self.x, self.y)] = 2
      self.refresh_agent_view()

  def move_down(self):
    self.direction = 'down'
    if self.x < len(self.explored_stage) - 1:
      if self.real_stage[(self.x + 1, self.y)] or self.explored_stage[(self.x + 1, self.y)]:  # obs or other agent
        print("obs")
        self.refresh_agent_view()
        return
      self.explored_stage[(self.x, self.y)] = 0
      self.x += 1
      self.explored_stage[(self.x, self.y)] = 2
      self.refresh_agent_view()

  def refresh_agent_view(self):
    # Generate agent view =======
    # Ex. If agent looks up -> knows both up, left and right (/w sensors).
    if self.direction == "up":
      if self.x > 0:
        if self.explored_stage[(self.x - 1, self.y)] < 0: # unexplored
          self.explored_stage[(self.x - 1, self.y)] = self.real_stage[(self.x - 1, self.y)]
      if self.y < len(self.real_stage[0]) - 1:
        if self.explored_stage[(self.x, self.y + 1)] < 0:
          self.explored_stage[(self.x, self.y + 1)] = self.real_stage[(self.x, self.y + 1)]
      if self.y > 0:
        if self.explored_stage[(self.x, self.y - 1)] < 0:
          self.explored_stage[(self.x, self.y - 1)] = self.real_stage[(self.x, self.y - 1)]

    elif self.direction == "down":
      if self.x < len(self.real_stage) - 1:
        if self.explored_stage[(self.x + 1, self.y)] < 0:
          self.explored_stage[(self.x + 1, self.y)] = self.real_stage[(self.x - 1, self.y)]
      if self.y < len(self.real_stage[0]) - 1:
        if self.explored_stage[(self.x, self.y + 1)] < 0:
          self.explored_stage[(self.x, self.y + 1)] = self.real_stage[(self.x, self.y + 1)]
      if self.y > 0:
        if self.explored_stage[(self.x, self.y - 1)] < 0:
          self.explored_stage[(self.x, self.y - 1)] = self.real_stage[(self.x, self.y - 1)]

    elif self.direction == "left":
      if self.y > 0:
        if self.explored_stage[(self.x, self.y - 1)] < 0:
          self.explored_stage[(self.x, self.y - 1)] = self.real_stage[(self.x, self.y - 1)]
      if self.x < len(self.real_stage) - 1:
        if self.explored_stage[(self.x + 1, self.y)] < 0:
          self.explored_stage[(self.x + 1, self.y)] = self.real_stage[(self.x + 1, self.y)]
      if self.x > 0:
        if self.explored_stage[(self.x - 1, self.y)] < 0:
          self.explored_stage[(self.x - 1, self.y)] = self.real_stage[(self.x - 1, self.y)]

    elif self.direction == "right":
      if self.y < len(self.real_stage[0]) - 1:
        if self.explored_stage[(self.x, self.y + 1)] < 0:
          self.explored_stage[(self.x, self.y + 1)] = self.real_stage[(self.x, self.y + 1)]
      if self.x < len(self.real_stage) - 1:
        if self.explored_stage[(self.x + 1, self.y)] < 0:
          self.explored_stage[(self.x + 1, self.y)] = self.real_stage[(self.x + 1, self.y)]
      if self.x > 0:
        if self.explored_stage[(self.x - 1, self.y)] < 0:
          self.explored_stage[(self.x - 1, self.y)] = self.real_stage[(self.x - 1, self.y)]

```

Check agent view:
"""

grid = np.array([[0, 0, 1, 0, 0],
                 [1, 0, 0, 2, 1],
                 [1, 0, 0, 1, 1],
                 [0, 0, 1, 0, 0],
                 [0, 0, 0, 0, 0]])

agents = [Agent((2, 2), (2, 2), grid, 2),]
res = move_astar(grid, agents)

import numpy as np

grid = np.array([[0, 0, -1, -1, 1],
                 [0, 2, 0, -1, -1],
                 [-1, 0, -1, -1, -1],
                 [-1, -1, -1, -1, -1],
                 [-1, 0, -1, -1, -1]])

coordinates = np.where(grid == 2)
x, y = coordinates[0][0], coordinates[1][0]

# print(grid[:x]) # up
# print(grid[x + 1:]) # down

# print(grid[:, y + 1:])  # right
# print(grid[:, :y])  # left

above_count = np.sum(grid[:x] == -1)
below_count = np.sum(grid[x + 1:] == -1)
right_count = np.sum(grid[:, y + 1:] == -1)
left_count = np.sum(grid[:, :y] == -1)

print(above_count, below_count, right_count, left_count)

l = [0, 1, 1, 0]
print(l.index(max(l)))